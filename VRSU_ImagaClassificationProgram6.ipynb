{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkaJdFQjE/t4h1UuniWQUl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himaja-56/VRSU/blob/main/VRSU_ImagaClassificationProgram6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bQXP2SCDyE_Q",
        "outputId": "1dc3f1d5-dbf5-4038-a500-febb3ce1bca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images: 1797\n",
            "Total number of labels: 1797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2760 - loss: 2.1895 - val_accuracy: 0.8500 - val_loss: 1.6269\n",
            "Epoch 2/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8367 - loss: 1.3646 - val_accuracy: 0.8917 - val_loss: 0.6470\n",
            "Epoch 3/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9163 - loss: 0.5395 - val_accuracy: 0.9250 - val_loss: 0.3590\n",
            "Epoch 4/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9404 - loss: 0.3192 - val_accuracy: 0.9472 - val_loss: 0.2361\n",
            "Epoch 5/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9469 - loss: 0.2233 - val_accuracy: 0.9556 - val_loss: 0.1892\n",
            "Epoch 6/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9575 - loss: 0.1860 - val_accuracy: 0.9639 - val_loss: 0.1569\n",
            "Epoch 7/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9772 - loss: 0.1332 - val_accuracy: 0.9639 - val_loss: 0.1434\n",
            "Epoch 8/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9720 - loss: 0.1194 - val_accuracy: 0.9722 - val_loss: 0.1161\n",
            "Epoch 9/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9705 - loss: 0.1134 - val_accuracy: 0.9694 - val_loss: 0.1009\n",
            "Epoch 10/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0861 - val_accuracy: 0.9722 - val_loss: 0.1029\n",
            "Epoch 11/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0738 - val_accuracy: 0.9806 - val_loss: 0.0930\n",
            "Epoch 12/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.0656 - val_accuracy: 0.9750 - val_loss: 0.0906\n",
            "Epoch 13/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9844 - loss: 0.0624 - val_accuracy: 0.9722 - val_loss: 0.0869\n",
            "Epoch 14/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0600 - val_accuracy: 0.9833 - val_loss: 0.0720\n",
            "Epoch 15/15\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0466 - val_accuracy: 0.9750 - val_loss: 0.0791\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0713 \n",
            "Model Accuracy: 0.9750000238418579\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6b0dc465-3343-4a90-9223-95b052908e8b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6b0dc465-3343-4a90-9223-95b052908e8b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving program5.jpeg to program5.jpeg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "Predicted Digit: 1\n"
          ]
        }
      ],
      "source": [
        "# CNN based Object recognition (Digit Classification)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from google.colab import files\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Load dataset\n",
        "digits = load_digits()\n",
        "X = digits.images\n",
        "y = digits.target\n",
        "\n",
        "print(\"Total number of images:\", X.shape[0])\n",
        "print(\"Total number of labels:\", y.shape[0])\n",
        "\n",
        "# Normalize and reshape for CNN\n",
        "X = X / 16.0\n",
        "X = X.reshape(-1, 8, 8, 1)\n",
        "\n",
        "y = to_categorical(y, 10)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(8,8,1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "# Upload image\n",
        "uploaded = files.upload()\n",
        "\n",
        "for file_name in uploaded.keys():\n",
        "    img = cv2.imread(file_name)\n",
        "\n",
        "# Convert to grayscale\n",
        "if len(img.shape) == 3:\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "else:\n",
        "    img_gray = img\n",
        "\n",
        "# Resize to 8x8\n",
        "img_resized = resize(img_gray, (8, 8), anti_aliasing=True)\n",
        "\n",
        "# Normalize & invert\n",
        "img_resized = img_resized / img_resized.max()\n",
        "img_resized = 1 - img_resized\n",
        "\n",
        "plt.imshow(img_resized, cmap='gray')\n",
        "plt.title(\"Processed Uploaded Image (8x8)\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Prepare for prediction\n",
        "img_resized = img_resized.reshape(1, 8, 8, 1)\n",
        "\n",
        "prediction = model.predict(img_resized)\n",
        "print(\"Predicted Digit:\", np.argmax(prediction))"
      ]
    }
  ]
}